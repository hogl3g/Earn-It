import fs from 'fs';
import path from 'path';

interface CalibrationData {
  a: number;
  b: number;
  sampleSize: number;
  status?: 'ok' | 'insufficient-variance' | 'small-sample';
  bucketMetrics?: Array<{ bucket: string; n: number; predAvg: number; hitRate: number }>;
}

interface GradeSummary {
  date: string;
  total_picks: number;
}

function interpretCalibrationStatus(calib: CalibrationData): string {
  if (calib.status === 'insufficient-variance') return 'âŒ DEGENERATE (no outcome variance)';
  if (calib.status === 'small-sample') return 'âš ï¸  UNRELIABLE (n<15)';
  if (calib.a === 1 && calib.b === 0) return 'âŒ IDENTITY (unchanged)';
  if (Math.abs(calib.b) > 2) return 'âš ï¸  EXTREME (steep slope)';
  if (calib.sampleSize < 5) return 'âŒ INSUFFICIENT (n<5)';
  if (calib.sampleSize < 15) return 'âš ï¸  SMALL (5â‰¤n<15)';
  if (calib.sampleSize < 30) return 'âœ“ MODERATE (15â‰¤n<30)';
  return 'âœ“ ROBUST (nâ‰¥30)';
}

function interpretFitQuality(calib: CalibrationData): { label: string; recommendation: string } {
  if (!calib.bucketMetrics || calib.bucketMetrics.length === 0) {
    return { label: 'UNKNOWN', recommendation: 'Insufficient bucket data to assess fit.' };
  }

  const buckets = calib.bucketMetrics;
  const calibErrors = buckets.map(b => Math.abs(b.predAvg - b.hitRate));
  const avgError = calibErrors.reduce((s, e) => s + e, 0) / calibErrors.length;
  const maxError = Math.max(...calibErrors);

  if (avgError < 0.05) return { label: 'â­ EXCELLENT', recommendation: 'Calibration is accurate; use full-Kelly sizing.' };
  if (avgError < 0.10) return { label: 'âœ“ GOOD', recommendation: 'Calibration is reasonably accurate; use half-Kelly.' };
  if (avgError < 0.15) return { label: 'âš ï¸  FAIR', recommendation: 'Calibration has moderate error; use quarter-Kelly or reduce stakes.' };
  return { label: 'âŒ POOR', recommendation: 'Calibration has high error; accumulate more data before relying on it.' };
}

function main() {
  const metaPath = decodeURIComponent(new URL(import.meta.url).pathname);
  const filePath = path.normalize(metaPath.replace(/^\//, ''));
  const workspace = path.resolve(path.dirname(filePath), '../..');
  const calibPath = path.join(workspace, 'data', 'results', 'clean', 'prob_calibration.json');

  if (!fs.existsSync(calibPath)) {
    console.log('\nğŸ“Š CALIBRATION STATUS DASHBOARD\n');
    console.log('âŒ No calibration file found:', calibPath);
    console.log('   â†’ Run: npx tsx server/cli/daily_refresh.ts');
    return;
  }

  const calib: CalibrationData = JSON.parse(fs.readFileSync(calibPath, 'utf8'));
  const statusMsg = interpretCalibrationStatus(calib);
  const fitQuality = interpretFitQuality(calib);

  console.log('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘          ğŸ“Š CALIBRATION STATUS DASHBOARD                       â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  console.log(`Status:          ${statusMsg}`);
  console.log(`Sample Size:     ${calib.sampleSize} games`);
  console.log(`Params:          f(p) = ${calib.a.toFixed(4)} + ${calib.b.toFixed(4)}Â·p`);

  console.log(`\nFit Quality:     ${fitQuality.label}`);
  console.log(`Recommendation:  ${fitQuality.recommendation}`);

  if (calib.bucketMetrics && calib.bucketMetrics.length > 0) {
    console.log('\nBucket Analysis:');
    console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
    console.log('Confidence   | Sample Size | Predicted | Actual   | Error');
    console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
    for (const b of calib.bucketMetrics) {
      const error = Math.abs(b.predAvg - b.hitRate);
      const predPct = (b.predAvg * 100).toFixed(1);
      const actualPct = (b.hitRate * 100).toFixed(1);
      const errorPct = (error * 100).toFixed(1);
      console.log(`${b.bucket.padEnd(12)} | ${String(b.n).padStart(11)} | ${predPct.padStart(8)}% | ${actualPct.padStart(7)}% | ${errorPct.padStart(5)}%`);
    }
  }

  console.log('\n\nInterpretation:');
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  if (calib.sampleSize < 15) {
    console.log('âš ï¸  Insufficient sample size for reliable calibration.');
    console.log('   Target: Accumulate 50+ graded games across overlapping dates.');
    console.log('   Current coverage is too small to trust recalibrated probabilities.');
  } else if (calib.a === 1 && calib.b === 0) {
    console.log('âš ï¸  Calibration is degenerate (identity mapping).');
    console.log('   This occurs when all outcomes are the same (all wins or all losses).');
    console.log('   Verify: Are the grades loaded and do they have enough variance?');
  } else {
    console.log('âœ“ Calibration fit is being tracked.');
    const direction = calib.b > 0 ? 'increases' : 'decreases';
    console.log(`   Fitted curve ${direction} with predicted probability.`);
    if (Math.abs(calib.b - 1) > 0.2) {
      console.log(`   Note: Slope differs from 1.0 (perfect calibration).`);
      if (calib.b < 1) {
        console.log(`   Interpretation: Model is overconfident (predicted > actual).`);
      } else {
        console.log(`   Interpretation: Model is underconfident (predicted < actual).`);
      }
    }
  }

  console.log('\nNext Steps:');
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  if (calib.sampleSize < 30) {
    console.log('1. Accumulate more graded games (target: 50+ samples)');
    console.log('2. Re-run: npx tsx server/cli/daily_refresh.ts');
    console.log('3. Check: npx tsx server/cli/calibration_status.ts');
  } else {
    console.log('1. Monitor calibration error weekly');
    console.log('2. If error > 10%, review model edge detection logic');
    console.log('3. If error < 5%, increase bet sizing confidence');
  }

  console.log('\n');
}

main();
